digraph {
	graph [size="12.15,12.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140151774721856 [label="
 (1, 256)" fillcolor=darkolivegreen1]
	140151742016544 [label=ReluBackward0]
	140151742015872 -> 140151742016544
	140151742015872 [label=AddmmBackward0]
	140151742011984 -> 140151742015872
	140151774712816 [label="linear.3.bias
 (256)" fillcolor=lightblue]
	140151774712816 -> 140151742011984
	140151742011984 [label=AccumulateGrad]
	140151742017168 -> 140151742015872
	140151742017168 [label=MulBackward0]
	140155335655328 -> 140151742017168
	140155335655328 [label=ReluBackward0]
	140155335653984 -> 140155335655328
	140155335653984 [label=AddmmBackward0]
	140155335653888 -> 140155335653984
	140151738883168 [label="linear.0.bias
 (256)" fillcolor=lightblue]
	140151738883168 -> 140155335653888
	140155335653888 [label=AccumulateGrad]
	140155335653936 -> 140155335653984
	140155335653936 [label=ViewBackward0]
	140155335655376 -> 140155335653936
	140155335655376 [label=ReluBackward0]
	140155335654464 -> 140155335655376
	140155335654464 [label=ConvolutionBackward0]
	140155335655232 -> 140155335654464
	140155335655232 [label=ReluBackward0]
	140155335654224 -> 140155335655232
	140155335654224 [label=ConvolutionBackward0]
	140155335654320 -> 140155335654224
	140155335654320 [label=ReluBackward0]
	140155335653792 -> 140155335654320
	140155335653792 [label=ConvolutionBackward0]
	140155335654608 -> 140155335653792
	140155335654608 [label=ReluBackward0]
	140155335945008 -> 140155335654608
	140155335945008 [label=ConvolutionBackward0]
	140155335948608 -> 140155335945008
	140151774714336 [label="cnn.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	140151774714336 -> 140155335948608
	140155335948608 [label=AccumulateGrad]
	140155335943664 -> 140155335945008
	140151774714176 [label="cnn.0.bias
 (32)" fillcolor=lightblue]
	140151774714176 -> 140155335943664
	140155335943664 [label=AccumulateGrad]
	140155335944000 -> 140155335653792
	140151774713936 [label="cnn.2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140151774713936 -> 140155335944000
	140155335944000 [label=AccumulateGrad]
	140155335935744 -> 140155335653792
	140151774713856 [label="cnn.2.bias
 (64)" fillcolor=lightblue]
	140151774713856 -> 140155335935744
	140155335935744 [label=AccumulateGrad]
	140155335653456 -> 140155335654224
	140151774713616 [label="cnn.4.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140151774713616 -> 140155335653456
	140155335653456 [label=AccumulateGrad]
	140155335654368 -> 140155335654224
	140151774713456 [label="cnn.4.bias
 (128)" fillcolor=lightblue]
	140151774713456 -> 140155335654368
	140155335654368 [label=AccumulateGrad]
	140155335654080 -> 140155335654464
	140151774713216 [label="cnn.6.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140151774713216 -> 140155335654080
	140155335654080 [label=AccumulateGrad]
	140155335654128 -> 140155335654464
	140151774713136 [label="cnn.6.bias
 (256)" fillcolor=lightblue]
	140151774713136 -> 140155335654128
	140155335654128 [label=AccumulateGrad]
	140155335654272 -> 140155335653984
	140155335654272 [label=TBackward0]
	140155335653840 -> 140155335654272
	140151739531328 [label="linear.0.weight
 (256, 160000)" fillcolor=lightblue]
	140151739531328 -> 140155335653840
	140155335653840 [label=AccumulateGrad]
	140151742016064 -> 140151742015872
	140151742016064 [label=TBackward0]
	140155335654416 -> 140151742016064
	140155336240928 [label="linear.3.weight
 (256, 256)" fillcolor=lightblue]
	140155336240928 -> 140155335654416
	140155335654416 [label=AccumulateGrad]
	140151742016544 -> 140151774721856
}
